{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/belenmichel/Desktop/MSCAPP/7_Machine Learning/4_FinalProject_Crimes/ml-nc-recidivism/source'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option(\"display.max_row\", 999)\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import requests\n",
    "import math\n",
    "import sys\n",
    "import graphviz \n",
    "import csv\n",
    "import sqlite3\n",
    "import re\n",
    "import codecs\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree as tr\n",
    "import os; os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_dir = \"../ncdoc_data/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pre-ProcessData\n",
    "\n",
    "def to_date(df, attribute_lst, years_range=[1800, 2100]):\n",
    "    '''\n",
    "    Converts the data type of a string in the format YYYY-MM-DD to a datetime  \n",
    "    '''\n",
    "    df = df.apply(out_of_range_to_none, axis=1, args=(years_range, attribute_lst))\n",
    "    for var in attribute_lst:\n",
    "        df[var] = df[var].astype('datetime64[s]')#, errors = 'ignore')\n",
    "    return df\n",
    "\n",
    "\n",
    "def out_of_range_to_none(row, year_range, column_lst): \n",
    "    '''\n",
    "    Converts a str representing a date out of the intended range to None\n",
    "    '''\n",
    "    for col in column_lst:\n",
    "        year = int(row[col].split(\"-\")[0])\n",
    "        if year < year_range[0] or year > year_range[1]:\n",
    "            row[col] = None \n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def to_int(df, attribute_lst):\n",
    "    '''\n",
    "    Converts the data type of a string in the format YYYY-MM-DD to a datetime  \n",
    "    '''\n",
    "    for var in attribute_lst:\n",
    "        df[var] = pd.to_numeric(df[var], errors='coerce', downcast='integer') \n",
    "    return df\n",
    "\n",
    "def remove_outliers(df, attribute_lst, sd_threshold=3):\n",
    "    '''\n",
    "    Takes a dataframe and number of standard deviations to be considered \n",
    "    as outlier and returns a df without the observation that have one or\n",
    "    or more outliers in it's attributes\n",
    "    input:\n",
    "        df: pandas data frame\n",
    "        sd_threshold: standard deviations\n",
    "    output:\n",
    "        the new datafrane without outliers\n",
    "    '''   \n",
    "    \n",
    "    return(df[(np.abs(stats.zscore(df[attribute_lst])) < sd_threshold).all(axis=1)])\n",
    "\n",
    "\n",
    "def fill_nan(df, attributes_lst):\n",
    "    '''\n",
    "    Fills the nan with the mean\n",
    "    input:\n",
    "        df: pandas data frame\n",
    "        attributes_lst: list of attributes names\n",
    "    output:\n",
    "        dataframe with the replaced nan\n",
    "    '''   \n",
    "    for attribute in attributes_lst: \n",
    "        df[attribute].fillna(df[attribute].mean(), inplace=True)\n",
    "\n",
    "def clean_str(col_names):\n",
    "    '''\n",
    "    Removes special characters from a string. \n",
    "    input:\n",
    "        col_names: string with column names\n",
    "    output:\n",
    "        sting where special characters where removed\n",
    "    ''' \n",
    "    #TODO: replace this ad-hoc function with a re function. \n",
    "    #col_names = re.sub(pattern, repl, string, count=0, flags=0) \n",
    "    col_names = col_names.replace('.','')\n",
    "    col_names = col_names.replace('#','')\n",
    "    col_names = col_names.replace('-','')\n",
    "    col_names = col_names.replace('(','')\n",
    "    col_names = col_names.replace(')','')\n",
    "    col_names = col_names.replace('&','')\n",
    "    col_names = col_names.replace('/','')\n",
    "    col_names = col_names.replace('__','')\n",
    "    return col_names\n",
    "\n",
    "\n",
    "# # Generate Features/ Predictors\n",
    "\n",
    "\n",
    "def discretize_variable(df, attribute_lst):\n",
    "    '''\n",
    "    Converts continuous variables into discrete variables\n",
    "    input:\n",
    "        df: pandas data frame\n",
    "        attributes_lst: list of attributes names\n",
    "    output:\n",
    "        dataframe with the new variables\n",
    "    ''' \n",
    "\n",
    "    for var in attribute_lst:\n",
    "        new_var = var + 'cat'\n",
    "        df[new_var] = pd.qcut(df[var], 10, duplicates=\"drop\", labels=False)\n",
    "    return df\n",
    "\n",
    "def categorical_to_dummy(df, attribute_lst):\n",
    "    '''\n",
    "    Converts categorical variables into one variabel dummies for each category. \n",
    "    input:\n",
    "        df: pandas data frame\n",
    "        attributes_lst: list of attributes names\n",
    "    output:\n",
    "        dataframe with the new variables\n",
    "    ''' \n",
    "\n",
    "    for var in attribute_lst:\n",
    "        df = pd.get_dummies(df, columns=[var])\n",
    "    return df\n",
    "\n",
    "def remove_attribute(df, attribute_lst):\n",
    "    '''\n",
    "    Removes attributes in the list from the data frame\n",
    "    '''     \n",
    "    return df.drop(attribute_lst, axis=1)\n",
    "\n",
    "def keep_attribute(df, attribute_lst):\n",
    "    '''\n",
    "    Keeps attributes in the list in the data frame\n",
    "    '''\n",
    "    df = df.loc[:, attribute_lst]\n",
    "    return df\n",
    "\n",
    "def flag_to_dummy(df, attribute_lst, rename=True):\n",
    "    '''\n",
    "    Converts a flag variable to a dummy with 1 for Yes and 0 for No\n",
    "    '''\n",
    "    for var in attribute_lst:\n",
    "        df[var] = df[var].map({'Y': 1, 'N': 0, 'Yes': 1, 'No': 0, 'T': 1, 'F': 0,\\\n",
    "                               'True': 1, 'False': 0, 'OPEN': 1, 'CLOSED': 0})\n",
    "        if rename:\n",
    "            new_var_name = var[:-5]\n",
    "            df.rename(index=str, columns={var: new_var_name}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def gender_to_dummy(df, gender_var):  \n",
    "    '''\n",
    "    Converts a gender indicative variable to a dummy with 1 for female and 0 for male\n",
    "    '''\n",
    "    df[gender_var] = df[gender_var].map({'FEMALE': 1, 'MALE': 0, 'F': 1, 'M': 0})\n",
    "    df.rename(index=str, columns={gender_var: \"FEMALE\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Inmate Profile\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/INMT4AA1.csv\")\n",
    "Inmate_Profile = pd.read_csv(file_name) #, nrows=400\n",
    "Inmate_Profile = Inmate_Profile[Inmate_Profile[\"INMATE_IS_FELON/MISDEMEANANT\"]==\"FELON\"]\n",
    "Inmate_Profile = flag_to_dummy(Inmate_Profile, ['ESCAPE_HISTORY_FLAG', 'PRIOR_INCARCERATIONS_FLAG'])\n",
    "Inmate_Profile = gender_to_dummy(Inmate_Profile, 'INMATE_GENDER_CODE')\n",
    "Inmate_Profile = categorical_to_dummy(Inmate_Profile, ['INMATE_RACE_CODE'])\n",
    "#Remove outliers for TOTAL_SENTENCE_LENGTHIN_DAYS, LENGTH_OF_CURRENT_INCARCERATN, LENGTH_OF_RULING_SENTENCES\n",
    "#Inmate_Profile = remove_outliers(Inmate_Profile, sd_threshold=3)\n",
    "Inmate_Profile = to_date(Inmate_Profile, [\"INMATE_BIRTH_DATE\",\"INMATE_ADMISSION_DATE\",\"FINAL_RULING_PED\",\\\n",
    "                              \"FINAL_RULING_TRD\", \"FINAL_RULING_PRD\", \"FINAL_RULING_MAX_RELEASE_DATE\",\\\n",
    "                              \"DATE_TRD_&_PRD_LAST_COMPUTED\", \"DATE_OF_LAST_ARREST_ON_PAROLE\"])\n",
    "Inmate_Profile[\"AGE_IN_DAYS\"] = Inmate_Profile[\"INMATE_ADMISSION_DATE\"] - Inmate_Profile[\"INMATE_BIRTH_DATE\"]\n",
    "Inmate_Profile = keep_attribute(Inmate_Profile, ['INMATE_DOC_NUMBER','INMATE_LAST_NAME','INMATE_FIRST_NAME',\\\n",
    "                                'FEMALE',\"INMATE_RACE_CODE_BLACK\", \"INMATE_RACE_CODE_INDIAN\",\\\n",
    "                                \"INMATE_RACE_CODE_OTHER\", \"INMATE_RACE_CODE_WHITE\",\"AGE_IN_DAYS\"\\\n",
    "                                'ESCAPE_HISTORY', 'PRIOR_INCARCERATIONS',\\\n",
    "                                \"INMATE_BIRTH_DATE\",\"INMATE_ADMISSION_DATE\",\"FINAL_RULING_PED\",\\\n",
    "                                \"FINAL_RULING_TRD\", \"FINAL_RULING_PRD\", \"FINAL_RULING_MAX_RELEASE_DATE\",\\\n",
    "                                \"DATE_TRD_&_PRD_LAST_COMPUTED\", \"DATE_OF_LAST_ARREST_ON_PAROLE\",\\\n",
    "                                \"TOTAL_SENTENCE_LENGTHIN_DAYS\", \"LENGTH_OF_CURRENT_INCARCERATN\",\\\n",
    "                                \"LENGTH_OF_RULING_SENTENCES\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Inmate_Profile.to_csv(new_file_name)\n",
    "\n",
    "#Shall we include?:\n",
    "#TYPE_OF_LAST_INMATE_MOVEMENT\n",
    "#MOST_SERIOUS_OFFNSE_CURR_INCAR\n",
    "\n",
    "#CURRENT_COMMITMENT_PREFIX\n",
    "#CURRENT_SENTENCE_COMPONENT\n",
    "\n",
    "#LAST_RULING_PRD_COMMITMENT\n",
    "#LAST_RULING_PRD_COMPONENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning SentenceComputation\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/INMT4BB1.csv\")\n",
    "Sentence_Computation = pd.read_csv(file_name, low_memory=False)\n",
    "Sentence_Computation = categorical_to_dummy(Sentence_Computation, ['INMATE_COMPUTATION_STATUS_FLAG'])\n",
    "Sentence_Computation = to_date(Sentence_Computation, [\"SENTENCE_BEGIN_DATE_(FOR_MAX)\",\"ACTUAL_SENTENCE_END_DATE\",\\\n",
    "                                          \"PROJECTED_RELEASE_DATE_(PRD)\",\"PAROLE_DISCHARGE_DATE\",\\\n",
    "                                          \"PAROLE_SUPERVISION_BEGIN_DATE\"])\n",
    "Sentence_Computation = keep_attribute(Sentence_Computation, [\"INMATE_DOC_NUMBER\",\"INMATE_COMMITMENT_PREFIX\",\"INMATE_SENTENCE_COMPONENT\",\\\n",
    "                                  \"SENTENCE_BEGIN_DATE_(FOR_MAX)\",\"ACTUAL_SENTENCE_END_DATE\",\\\n",
    "                                  \"PROJECTED_RELEASE_DATE_(PRD)\",\"PAROLE_DISCHARGE_DATE\",\\\n",
    "                                  \"PAROLE_SUPERVISION_BEGIN_DATE\",\"INMATE_COMPUTATION_STATUS_FLAG_ACTIVE\",\\\n",
    "                                  \"INMATE_COMPUTATION_STATUS_FLAG_EAR.TERM\",\"INMATE_COMPUTATION_STATUS_FLAG_EXPIRED\",\\\n",
    "                                  \"INMATE_COMPUTATION_STATUS_FLAG_FUTURE\",\"INMATE_COMPUTATION_STATUS_FLAG_PAROLED\",\\\n",
    "                                  \"INMATE_COMPUTATION_STATUS_FLAG_POST REL\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Sentence_Computation.to_csv(new_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Disciplinary Infraction Charge\n",
    "file_name = os.path.join(data_dir, \"preprocessed/INMT9CF1.csv\")\n",
    "Infraction_Charge = pd.read_csv(file_name, low_memory=False)\n",
    "Infraction_Charge = categorical_to_dummy(Infraction_Charge, ['DISCIPLINARY_CHARGE_LEVEL'])\n",
    "Infraction_Charge = flag_to_dummy(Infraction_Charge, [\"ACTIVATE_PRIOR_SUSPENSION\"], rename=False)\n",
    "Infraction_Charge =keep_attribute(Infraction_Charge, [\"INMATE_DOC_NUMBER\", \"DISCIPLINARY_CHARGE_LEVEL_APPEAL\",\\\n",
    "                                   \"DISCIPLINARY_CHARGE_LEVEL_DISCP HEAR OFFC\",\\\n",
    "                                   \"DISCIPLINARY_CHARGE_LEVEL_UNIT\",'ACTIVATE_PRIOR_SUSPENSION'])\n",
    "#Shall we include?:\n",
    "#'DISCIPLINARY_APPEAL_DECISION'\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Infraction_Charge.to_csv(new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Financial_Obligation\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/OFNT1BA1.csv\")\n",
    "Financial_Obligation = pd.read_csv(file_name, low_memory=False)\n",
    "Financial_Obligation = categorical_to_dummy(Financial_Obligation, [\"COURT_ORDERED_PAYMENT_TYPE\"])\n",
    "Financial_Obligation = flag_to_dummy(Financial_Obligation, [\"PAYEE_ACCOUNT_STATUS_CODE\"], rename=False)\n",
    "#Financial_Obligation = discretize_variable(Financial_Obligation, [\"COP_BALANCE\"])\n",
    "Financial_Obligation = keep_attribute(Financial_Obligation, [\"OFFENDER_NC_DOC_ID_NUMBER\", \"COP_COMMITMENT_PREFIX\",\\\n",
    "                                      \"COP_ACCOUNT_SEQUENCE_NUMBER\",\"COURT_ORDERED_PAYMENT_TYPE_FINE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_COMM. SERVICE FEE\",\"PAYEE_ACCOUNT_STATUS_CODE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_COURT COSTS\",\"COURT_ORDERED_PAYMENT_TYPE_JAIL FEE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_JUDGEMENT\",\"COURT_ORDERED_PAYMENT_TYPE_RESTITUTION\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_SUPERVISION FEE\", \"COP_BALANCEcat\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Financial_Obligation.to_csv(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Court Commitment\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/OFNT3BB1.csv\")\n",
    "Court_Commitment = pd.read_csv(file_name, low_memory=False, nrows=40000)\n",
    "Court_Commitment\n",
    "Court_Commitment = categorical_to_dummy(Court_Commitment, [\"COURT_ORDERED_PAYMENT_TYPE\"])\n",
    "Court_Commitment = flag_to_dummy(Court_Commitment, [\"PAYEE_ACCOUNT_STATUS_CODE\"], rename=False)\n",
    "#Court_Commitment = discretize_variable(Court_Commitment, [\"COP_BALANCE\"])\n",
    "Court_Commitment =  keep_attribute(Court_Commitment, [\"OFFENDER_NC_DOC_ID_NUMBER\", \"COP_COMMITMENT_PREFIX\",\\\n",
    "                                      \"COP_ACCOUNT_SEQUENCE_NUMBER\",\"COURT_ORDERED_PAYMENT_TYPE_FINE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_COMM. SERVICE FEE\",\"PAYEE_ACCOUNT_STATUS_CODE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_COURT COSTS\",\"COURT_ORDERED_PAYMENT_TYPE_JAIL FEE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_JUDGEMENT\",\"COURT_ORDERED_PAYMENT_TYPE_RESTITUTION\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_SUPERVISION FEE\", \"COP_BALANCEcat\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Court_Commitment.to_csv(new_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Sentence_Component\n",
    "\n",
    "file_name =  os.path.join(data_dir, \"preprocessed/OFNT3CE1.csv\")\n",
    "Sentence_Component = pd.read_csv(file_name, low_memory=False)#, nrows=40000)\n",
    "\n",
    "#I don't think we want to filter by FELON:\n",
    "#Sentence_Component = Sentence_Component[Sentence_Component[\"PRIMARY_FELONY/MISDEMEANOR_CD.\"]==\"FELON\"]\n",
    "Sentence_Component = to_int(Sentence_Component, [\"MAXIMUM_SENTENCE_LENGTH\"])\n",
    "Sentence_Component = categorical_to_dummy(Sentence_Component, [\"PRIMARY_FELONY/MISDEMEANOR_CD.\",\\\n",
    "                                                               \"PUNISHMENT_TYPE_CODE\",\\\n",
    "                                                               \"COURT_TYPE_CODE\",\\\n",
    "                                                               \"COMPONENT_DISPOSITION_CODE\",\\\n",
    "                                                               \"OFFENSE_QUALIFIER_CODE\",\\\n",
    "                                                               \"INMATE_SENTENCE_STATUS_CODE\",\\\n",
    "                                                               \"SERVING_MIN_OR_MAX_TERM_CODE\"])\n",
    "Sentence_Component = to_date(Sentence_Component, [\"DATE_OFFENSE_COMMITTED_-_BEGIN\",\\\n",
    "                                                  \"SENTENCE_EFFECTIVE(BEGIN)_DATE\",\\\n",
    "                                                  \"INMATE_COMPONENT_STATUS_DATE\"])\n",
    "Sentence_Component = keep_attribute(Sentence_Component,['OFFENDER_NC_DOC_ID_NUMBER', 'COMMITMENT_PREFIX',\\\n",
    "                                   'SENTENCE_COMPONENT_NUMBER', 'COUNTY_OF_CONVICTION_CODE',\\\n",
    "                                   'PRIMARY_OFFENSE_CODE', 'DATE_OFFENSE_COMMITTED_-_BEGIN',\\\n",
    "                                   'MINIMUM_SENTENCE_LENGTH', 'MAXIMUM_SENTENCE_LENGTH',\\\n",
    "                                   'LENGTH_OF_SUPERVISION', 'SENTENCE_EFFECTIVE(BEGIN)_DATE',\\\n",
    "                                   'INMATE_COMPONENT_STATUS_DATE', 'PRIMARY_FELONY/MISDEMEANOR_CD._FELON',\\\n",
    "                                   'PRIMARY_FELONY/MISDEMEANOR_CD._MISD.',\\\n",
    "                                   'PRIMARY_FELONY/MISDEMEANOR_CD._UNKN.',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_ACTIVE  SS',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_COMMUNITY SS (DCC)', 'PUNISHMENT_TYPE_CODE_DWI',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_FAIR FELONS',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_FAIR MISDEMEAN',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_INTERMEDIATE SS',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_NON JUDGMENT CASES',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_NON-N.C. OFF.',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_POST RELEASE', 'PUNISHMENT_TYPE_CODE_PRE-FAIR',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_PRE-SS (FAIR) DCC', 'PUNISHMENT_TYPE_CODE_PSI',\\\n",
    "                                   'COURT_TYPE_CODE_CO RECORDR', 'COURT_TYPE_CODE_DISTRICT',\\\n",
    "                                   'COURT_TYPE_CODE_DOMES RELA', 'COURT_TYPE_CODE_ICC/OS/FED',\\\n",
    "                                   'COURT_TYPE_CODE_J.P.', 'COURT_TYPE_CODE_MAGISTRAT',\\\n",
    "                                   'COURT_TYPE_CODE_MAYORS', 'COURT_TYPE_CODE_SUPERIOR',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_APPEAL',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_BENCH TRIAL',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_CRV/3M',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_GUILTY',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_JUDGMENT',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_JURY TRIAL',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_NEGOTIATED PLEA',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_NOLO CONTENDRE',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_NON-JUDGMENT',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_NOT GUILTY',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_PARTIAL REVOKE',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_POST REL. REVOKED',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_UNKNOWN',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_ACCES A/F', 'OFFENSE_QUALIFIER_CODE_ACCES ATT',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_ACCES B/F', 'OFFENSE_QUALIFIER_CODE_AID&ABET',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_ATTEMPTED', 'OFFENSE_QUALIFIER_CODE_CONSPI ATT',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_CONSPIRACY', 'OFFENSE_QUALIFIER_CODE_PRINCIPAL',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_SOLIC ATT', 'OFFENSE_QUALIFIER_CODE_SOLICIT',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_UNKNOWN', 'INMATE_SENTENCE_STATUS_CODE_ACTIVE',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_AMENDED',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_ARRESTED',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_CANCEL',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_COMM T/S',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_COMMUTAT',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_CORRECT',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_COURT OR',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_DISMISS',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_MODIFIED',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_P & T',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_PAR CONS',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_PARDON',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_PC TERM',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_QUASHED',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_REINSTATE',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_RESENTEN',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_VACATED',\\\n",
    "                                   'SERVING_MIN_OR_MAX_TERM_CODE_MAX.TERM:',\\\n",
    "                                   'SERVING_MIN_OR_MAX_TERM_CODE_MIN.TERM:'])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Sentence_Component.to_csv(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Special_Cond_Sanctions\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/OFNT3DE1.csv\")\n",
    "Special_Cond = pd.read_csv(file_name, low_memory=False)#, nrows=40000)\n",
    "Special_Cond = keep_attribute(Special_Cond,[\"OFFENDER_NC_DOC_ID_NUMBER\",\\\n",
    "                                            \"COMMITMENT_PREFIX\",\\\n",
    "                                            \"SENTENCE_COMPONENT_NUMBER\",\\\n",
    "                                            \"SPECIAL_PROVISION/SANCTION_CD\",\\\n",
    "                                            \"COMPLETION_STATUS_OF_SANCTION\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Special_Cond.to_csv(new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Parole_Analyst\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/INMT4CA1.csv\")\n",
    "Parole_Analyst = pd.read_csv(file_name, low_memory=False)#, nrows=40000)\n",
    "Parole_Analyst = categorical_to_dummy(Parole_Analyst, ['NEXT_PAROLE_REVIEW_TYPE_CODE'])\n",
    "Parole_Analyst = to_date(Parole_Analyst, [\"RELEASE_DATE_(PAROLE_REVIEW)\"])\n",
    "Parole_Analyst = keep_attribute(Parole_Analyst,   ['INMATE_DOC_NUMBER', 'RELEASE_DATE_(PAROLE_REVIEW)',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_AFTERCARE TRT.',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_COMMISSION REVW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_INTERIM REVIEW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_MAPP REVIEW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_PAROLE REVIEW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_RT DRUG TEST',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_VOTE REVIEW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_WORK RELEASE'])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Parole_Analyst.to_csv(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(os.path.join(data_dir, \"crimes.db\"))\n",
    "cur = con.cursor()\n",
    "\n",
    "tables = ['INMT4AA1_cleaned', 'INMT4BB1_cleaned', 'INMT9CF1_cleaned',\\\n",
    "          'OFNT1BA1_cleaned', 'OFNT3BB1_cleaned', 'OFNT3CE1_cleaned',\\\n",
    "          'OFNT3DE1_cleaned', 'INMT4CA1_cleaned']\n",
    "\n",
    "for table in tables:\n",
    "    #print(table)\n",
    "    file_name = \"data/preprocessed/{}.csv\".format(table)\n",
    "    col_names = pd.read_csv(file_name, nrows=0).columns\n",
    "    n_columns = len(col_names)\n",
    "    col_names = clean_str(', '.join(col_names))\n",
    "    cur.execute('DROP TABLE IF EXISTS {}'.format(table))\n",
    "    cur.execute(\"CREATE TABLE {} ({});\".format(table, col_names))\n",
    "    \n",
    "    #File contains NULL bytes. That's why I replaced '\\0' with ''\n",
    "    reader = csv.reader(x.replace('\\0','') for x in open(file_name))\n",
    "    for row in reader:\n",
    "        row = [None if x == '' else x for x in row]\n",
    "        cur.execute(\"INSERT INTO {} VALUES ({});\".format(table,\",\".join(['?']*n_columns)), row)\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER:\n",
    "'''\n",
    "Warrant_Issued = pd.read_csv(\"data/preprocessed/OFNT9BE1.csv\")\n",
    "Offender_profile = pd.read_csv(\"data/preprocessed/OFNT3AA1.csv\")\n",
    "\n",
    "Infraction_Charge.groupby(\"SUSPENSION_STATUS\").size()\n",
    "\n",
    "#Print type of data on the df:\n",
    "\n",
    "for at in Inmate_Profile.columns:\n",
    "    print(at)\n",
    "    print(type(Inmate_Profile[at][0]))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
