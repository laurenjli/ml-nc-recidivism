{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/belenmichel/Desktop/MSCAPP/7_Machine Learning/4_FinalProject_Crimes/ml-nc-recidivism/source'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option(\"display.max_row\", 999)\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import requests\n",
    "import math\n",
    "import sys\n",
    "import graphviz \n",
    "import csv\n",
    "import sqlite3\n",
    "import re\n",
    "import codecs\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree as tr\n",
    "import os; os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_dir = \"../ncdoc_data/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pre-ProcessData\n",
    "\n",
    "def to_date(df, attribute_lst, years_range=[1800, 2100]):\n",
    "    '''\n",
    "    Converts the data type of a string in the format YYYY-MM-DD to a datetime  \n",
    "    '''\n",
    "    df = df.apply(out_of_range_to_none, axis=1, args=(years_range, attribute_lst))\n",
    "    for var in attribute_lst:\n",
    "        df[var] = df[var].astype('datetime64[s]')#, errors = 'ignore')\n",
    "    return df\n",
    "\n",
    "\n",
    "def out_of_range_to_none(row, year_range, attributes_lst): \n",
    "    '''\n",
    "    Converts a str representing a date out of the intended range to None\n",
    "    '''\n",
    "    for col in attributes_lst:\n",
    "        year = int(row[col].split(\"-\")[0])\n",
    "        if year < year_range[0] or year > year_range[1]:\n",
    "            row[col] = None \n",
    "    return row\n",
    "\n",
    "\n",
    "def to_int(df, attribute_lst):\n",
    "    '''\n",
    "    Converts the data type of a string to an integer if possible or other type of number.  \n",
    "    '''\n",
    "    for var in attribute_lst:\n",
    "        df[var] = pd.to_numeric(df[var], errors='coerce', downcast='integer') \n",
    "    return df\n",
    "\n",
    "def remove_outliers(df, attribute_lst, sd_threshold=3):\n",
    "    '''\n",
    "    Takes a dataframe and number of standard deviations to be considered \n",
    "    as outlier and returns a df without the observation that have one or\n",
    "    or more outliers in the attributes selected.\n",
    "    input:\n",
    "        df: pandas data frame\n",
    "        attributes_lst: list of attributes names\n",
    "        sd_threshold: standard deviations\n",
    "    output:\n",
    "        the new datafrane without outliers\n",
    "    '''   \n",
    "    \n",
    "    return(df[(np.abs(stats.zscore(df[attribute_lst])) < sd_threshold).all(axis=1)])\n",
    "\n",
    "\n",
    "def fill_nan(df, attributes_lst):\n",
    "    '''\n",
    "    Fills the nan with the mean\n",
    "    input:\n",
    "        df: pandas data frame\n",
    "        attributes_lst: list of attributes names\n",
    "    output:\n",
    "        dataframe with the replaced nan\n",
    "    '''   \n",
    "    for attribute in attributes_lst: \n",
    "        df[attribute].fillna(df[attribute].mean(), inplace=True)\n",
    "\n",
    "def clean_str(col_names):\n",
    "    '''\n",
    "    Removes special characters from a string. \n",
    "    input:\n",
    "        col_names: string with column names\n",
    "    output:\n",
    "        sting where special characters where removed\n",
    "    ''' \n",
    "    #TODO: replace this ad-hoc function with a re function. \n",
    "    #col_names = re.sub(pattern, repl, string, count=0, flags=0) \n",
    "    col_names = col_names.replace('.','')\n",
    "    col_names = col_names.replace('#','')\n",
    "    col_names = col_names.replace('-','')\n",
    "    col_names = col_names.replace('(','')\n",
    "    col_names = col_names.replace(')','')\n",
    "    col_names = col_names.replace('&','')\n",
    "    col_names = col_names.replace('/','')\n",
    "    col_names = col_names.replace(':','')\n",
    "    col_names = col_names.replace(' ','')\n",
    "    col_names = col_names.replace('__','')\n",
    "    return col_names\n",
    "\n",
    "\n",
    "# # Generate Features/ Predictors\n",
    "\n",
    "\n",
    "def discretize_variable(df, attribute_lst):\n",
    "    '''\n",
    "    Converts continuous variables into discrete variables\n",
    "    input:\n",
    "        df: pandas data frame\n",
    "        attributes_lst: list of attributes names\n",
    "    output:\n",
    "        dataframe with the new variables\n",
    "    ''' \n",
    "\n",
    "    for var in attribute_lst:\n",
    "        new_var = var + 'cat'\n",
    "        df[new_var] = pd.qcut(df[var], 10, duplicates=\"drop\", labels=False)\n",
    "    return df\n",
    "\n",
    "def categorical_to_dummy(df, attribute_lst):\n",
    "    '''\n",
    "    Converts categorical variables into one variabel dummies for each category. \n",
    "    input:\n",
    "        df: pandas data frame\n",
    "        attributes_lst: list of attributes names\n",
    "    output:\n",
    "        dataframe with the new variables\n",
    "    ''' \n",
    "\n",
    "    for var in attribute_lst:\n",
    "        df = pd.get_dummies(df, columns=[var])\n",
    "    return df\n",
    "\n",
    "def remove_attribute(df, attribute_lst):\n",
    "    '''\n",
    "    Removes attributes in the list from the data frame\n",
    "    '''     \n",
    "    return df.drop(attribute_lst, axis=1)\n",
    "\n",
    "def keep_attribute(df, attribute_lst):\n",
    "    '''\n",
    "    Keeps attributes in the list in the data frame\n",
    "    '''\n",
    "    df = df.loc[:, attribute_lst]\n",
    "    return df\n",
    "\n",
    "def flag_to_dummy(df, attribute_lst, rename=True):\n",
    "    '''\n",
    "    Converts a flag variable to a dummy with 1 for Yes and 0 for No\n",
    "    '''\n",
    "    for var in attribute_lst:\n",
    "        df[var] = df[var].map({'Y': 1, 'N': 0, 'Yes': 1, 'No': 0, 'T': 1, 'F': 0,\\\n",
    "                               'True': 1, 'False': 0, 'OPEN': 1, 'CLOSED': 0})\n",
    "        if rename:\n",
    "            new_var_name = var[:-5]\n",
    "            df.rename(index=str, columns={var: new_var_name}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def gender_to_dummy(df, gender_var):  \n",
    "    '''\n",
    "    Converts a gender indicative variable to a dummy with 1 for female and 0 for male\n",
    "    '''\n",
    "    df[gender_var] = df[gender_var].map({'FEMALE': 1, 'MALE': 0, 'F': 1, 'M': 0})\n",
    "    df.rename(index=str, columns={gender_var: \"FEMALE\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIOR_INCARCERATIONS_FLAG\n",
       "N      4\n",
       "Y    396\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = os.path.join(data_dir, \"preprocessed/INMT4AA1.csv\")\n",
    "Inmate_Profile = pd.read_csv(file_name, nrows=400)\n",
    "Inmate_Profile.groupby('PRIOR_INCARCERATIONS_FLAG').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0,25,26,53,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Cleaning Inmate Profile\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/INMT4AA1.csv\")\n",
    "Inmate_Profile = pd.read_csv(file_name) #, nrows=400\n",
    "Inmate_Profile = Inmate_Profile[Inmate_Profile[\"INMATE_IS_FELON/MISDEMEANANT\"]==\"FELON\"]\n",
    "Inmate_Profile = flag_to_dummy(Inmate_Profile, ['ESCAPE_HISTORY_FLAG', 'PRIOR_INCARCERATIONS_FLAG'])\n",
    "Inmate_Profile = gender_to_dummy(Inmate_Profile, 'INMATE_GENDER_CODE')\n",
    "Inmate_Profile = categorical_to_dummy(Inmate_Profile, ['INMATE_RACE_CODE'])\n",
    "#Remove outliers for TOTAL_SENTENCE_LENGTHIN_DAYS, LENGTH_OF_CURRENT_INCARCERATN, LENGTH_OF_RULING_SENTENCES\n",
    "#Inmate_Profile = remove_outliers(Inmate_Profile, sd_threshold=3)\n",
    "Inmate_Profile = to_date(Inmate_Profile, [\"INMATE_BIRTH_DATE\",\"INMATE_ADMISSION_DATE\",\"FINAL_RULING_PED\",\\\n",
    "                                          \"FINAL_RULING_TRD\", \"FINAL_RULING_PRD\", \"FINAL_RULING_MAX_RELEASE_DATE\",\\\n",
    "                                          \"DATE_TRD_&_PRD_LAST_COMPUTED\", \"DATE_OF_LAST_ARREST_ON_PAROLE\"])\n",
    "Inmate_Profile[\"AGE_IN_DAYS\"] = Inmate_Profile[\"INMATE_ADMISSION_DATE\"] - Inmate_Profile[\"INMATE_BIRTH_DATE\"]\n",
    "\n",
    "Inmate_Profile = keep_attribute(Inmate_Profile,['INMATE_DOC_NUMBER', 'INMATE_LAST_NAME', 'INMATE_FIRST_NAME',\\\n",
    "                                                'FEMALE', 'INMATE_BIRTH_DATE',  'INMATE_RACE_CODE_ASIAN/ORTL',\\\n",
    "                                                'INMATE_ADMISSION_DATE', 'FINAL_RULING_PED', 'FINAL_RULING_TRD',\\\n",
    "                                                'FINAL_RULING_PRD', 'FINAL_RULING_MAX_RELEASE_DATE',\\\n",
    "                                                'DATE_TRD_&_PRD_LAST_COMPUTED', 'MOST_SERIOUS_OFFNSE_CURR_INCAR',\\\n",
    "                                                'DAYS_SERVED_IN_DOC_CUSTODY', 'DATE_OF_LAST_ARREST_ON_PAROLE',\\\n",
    "                                                'TOTAL_SENTENCE_LENGTH(IN_DAYS)', 'LENGTH_OF_CURRENT_INCARCERATN.',\\\n",
    "                                                'ESCAPE_HISTORY', 'PRIOR_INCARCERATIONS', 'LENGTH_OF_RULING_SENTENCES',\\\n",
    "                                                'CURRENT_COMMITMENT_PREFIX', 'CURRENT_SENTENCE_COMPONENT',\\\n",
    "                                                'INMATE_RACE_CODE_BLACK', 'INMATE_RACE_CODE_INDIAN',\\\n",
    "                                                'INMATE_RACE_CODE_OTHER', 'INMATE_RACE_CODE_UNKNOWN',\\\n",
    "                                                'INMATE_RACE_CODE_WHITE', 'AGE_IN_DAYS'])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Inmate_Profile.to_csv(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PRIOR_INCARCERATIONS\n",
       "0.0     10829\n",
       "1.0    282966\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(10829+282966)\n",
    "Inmate_Profile.groupby('PRIOR_INCARCERATIONS').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning SentenceComputation\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/INMT4BB1.csv\")\n",
    "Sentence_Computation = pd.read_csv(file_name, low_memory=False)\n",
    "\n",
    "Sentence_Computation = categorical_to_dummy(Sentence_Computation, ['INMATE_COMPUTATION_STATUS_FLAG'])\n",
    "\n",
    "Sentence_Computation = to_date(Sentence_Computation, [\"SENTENCE_BEGIN_DATE_(FOR_MAX)\",\"ACTUAL_SENTENCE_END_DATE\",\\\n",
    "                                          \"PROJECTED_RELEASE_DATE_(PRD)\",\"PAROLE_DISCHARGE_DATE\",\\\n",
    "                                          \"PAROLE_SUPERVISION_BEGIN_DATE\"])\n",
    "Sentence_Computation['RELEASE_DATE'] = Sentence_Computation[[\"ACTUAL_SENTENCE_END_DATE\", \"PROJECTED_RELEASE_DATE_(PRD)\"]].max(axis=1)\n",
    "Sentence_Computation['RELEASE_365DAYS_DATE'] = Sentence_Computation['ACTUAL_SENTENCE_END_DATE'].apply(lambda x: x + pd.DateOffset(years=1))\n",
    "Sentence_Computation['RELEASE_YEAR'] = Sentence_Computation['ACTUAL_SENTENCE_END_DATE'].dt.year\n",
    "Sentence_Computation['BEGIN_YEAR'] = Sentence_Computation['SENTENCE_BEGIN_DATE_(FOR_MAX)'].dt.year\n",
    "Sentence_Computation = keep_attribute(Sentence_Computation, [\"INMATE_DOC_NUMBER\",\"INMATE_COMMITMENT_PREFIX\",\"INMATE_SENTENCE_COMPONENT\",\\\n",
    "                                  \"SENTENCE_BEGIN_DATE_(FOR_MAX)\",\"ACTUAL_SENTENCE_END_DATE\",\\\n",
    "                                  \"PROJECTED_RELEASE_DATE_(PRD)\",\"PAROLE_DISCHARGE_DATE\",\\\n",
    "                                  \"PAROLE_SUPERVISION_BEGIN_DATE\",\"INMATE_COMPUTATION_STATUS_FLAG_ACTIVE\",\\\n",
    "                                  \"INMATE_COMPUTATION_STATUS_FLAG_EAR.TERM\",\"INMATE_COMPUTATION_STATUS_FLAG_EXPIRED\",\\\n",
    "                                  \"INMATE_COMPUTATION_STATUS_FLAG_FUTURE\",\"INMATE_COMPUTATION_STATUS_FLAG_PAROLED\",\\\n",
    "                                  \"INMATE_COMPUTATION_STATUS_FLAG_POST REL\", \"RELEASE_DATE\", \"RELEASE_YEAR\",\\\n",
    "                                  \"RELEASE_365DAYS_DATE\",'BEGIN_YEAR'])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Sentence_Computation.to_csv(new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Disciplinary Infraction Charge\n",
    "file_name = os.path.join(data_dir, \"preprocessed/INMT9CF1.csv\")\n",
    "Infraction_Charge = pd.read_csv(file_name, low_memory=False)\n",
    "Infraction_Charge = categorical_to_dummy(Infraction_Charge, ['DISCIPLINARY_CHARGE_LEVEL'])\n",
    "Infraction_Charge = flag_to_dummy(Infraction_Charge, [\"ACTIVATE_PRIOR_SUSPENSION\"], rename=False)\n",
    "Infraction_Charge =keep_attribute(Infraction_Charge, [\"INMATE_DOC_NUMBER\", \"DISCIPLINARY_CHARGE_LEVEL_APPEAL\",\\\n",
    "                                   \"DISCIPLINARY_CHARGE_LEVEL_DISCP HEAR OFFC\",\\\n",
    "                                   \"DISCIPLINARY_CHARGE_LEVEL_UNIT\",'ACTIVATE_PRIOR_SUSPENSION'])\n",
    "#Shall we include?:\n",
    "#'DISCIPLINARY_APPEAL_DECISION'\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Infraction_Charge.to_csv(new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "#Cleaning Financial_Obligation\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/OFNT1BA1.csv\")\n",
    "Financial_Obligation = pd.read_csv(file_name, low_memory=False)\n",
    "Financial_Obligation = categorical_to_dummy(Financial_Obligation, [\"COURT_ORDERED_PAYMENT_TYPE\"])\n",
    "Financial_Obligation = flag_to_dummy(Financial_Obligation, [\"PAYEE_ACCOUNT_STATUS_CODE\"], rename=False)\n",
    "#Financial_Obligation = discretize_variable(Financial_Obligation, [\"COP_BALANCE\"])\n",
    "Financial_Obligation = keep_attribute(Financial_Obligation, [\"OFFENDER_NC_DOC_ID_NUMBER\", \"COP_COMMITMENT_PREFIX\",\\\n",
    "                                      \"COP_ACCOUNT_SEQUENCE_NUMBER\",\"COURT_ORDERED_PAYMENT_TYPE_FINE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_COMM. SERVICE FEE\",\"PAYEE_ACCOUNT_STATUS_CODE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_COURT COSTS\",\"COURT_ORDERED_PAYMENT_TYPE_JAIL FEE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_JUDGEMENT\",\"COURT_ORDERED_PAYMENT_TYPE_RESTITUTION\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_SUPERVISION FEE\", \"COP_BALANCEcat\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Financial_Obligation.to_csv(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Court Commitment\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/OFNT3BB1.csv\")\n",
    "Court_Commitment = pd.read_csv(file_name, low_memory=False)#, nrows=40000)\n",
    "#Court_Commitment = categorical_to_dummy(Court_Commitment, [\"MOST_SERIOUS_OFFENSE_CODE\"]) #TODO:convert to types of offenses\n",
    "Court_Commitment = flag_to_dummy(Court_Commitment, [\"NEW_PERIOD_OF_INCARCERATION_FL\"], rename=False)\n",
    "#Court_Commitment = discretize_variable(Court_Commitment, [\"TOTAL_SENTENCE_LENGTH\"])\n",
    "Court_Commitment =  keep_attribute(Court_Commitment, [\"OFFENDER_NC_DOC_ID_NUMBER\",\\\n",
    "                                                      \"COMMITMENT_PREFIX\",\\\n",
    "                                                      \"NEW_PERIOD_OF_INCARCERATION_FL\",\\\n",
    "                                                      \"MOST_SERIOUS_OFFENSE_CODE\",\\\n",
    "                                                      \"TOTAL_SENTENCE_LENGTH\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Court_Commitment.to_csv(new_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Sentence_Component\n",
    "\n",
    "file_name =  os.path.join(data_dir, \"preprocessed/OFNT3CE1.csv\")\n",
    "Sentence_Component = pd.read_csv(file_name, low_memory=False)#, nrows=40000)\n",
    "\n",
    "#I don't think we want to filter by FELON:\n",
    "#Sentence_Component = Sentence_Component[Sentence_Component[\"PRIMARY_FELONY/MISDEMEANOR_CD.\"]==\"FELON\"]\n",
    "Sentence_Component = to_int(Sentence_Component, [\"MAXIMUM_SENTENCE_LENGTH\"])\n",
    "Sentence_Component = categorical_to_dummy(Sentence_Component, [\"PRIMARY_FELONY/MISDEMEANOR_CD.\",\\\n",
    "                                                               \"PUNISHMENT_TYPE_CODE\",\\\n",
    "                                                               \"COURT_TYPE_CODE\",\\\n",
    "                                                               \"COMPONENT_DISPOSITION_CODE\",\\\n",
    "                                                               \"OFFENSE_QUALIFIER_CODE\",\\\n",
    "                                                               \"INMATE_SENTENCE_STATUS_CODE\",\\\n",
    "                                                               \"SERVING_MIN_OR_MAX_TERM_CODE\"])\n",
    "Sentence_Component = to_date(Sentence_Component, [\"DATE_OFFENSE_COMMITTED_-_BEGIN\",\\\n",
    "                                                  \"SENTENCE_EFFECTIVE(BEGIN)_DATE\",\\\n",
    "                                                  \"INMATE_COMPONENT_STATUS_DATE\"])\n",
    "Sentence_Component = keep_attribute(Sentence_Component,['OFFENDER_NC_DOC_ID_NUMBER', 'COMMITMENT_PREFIX',\\\n",
    "                                   'SENTENCE_COMPONENT_NUMBER', 'COUNTY_OF_CONVICTION_CODE',\\\n",
    "                                   'PRIMARY_OFFENSE_CODE', 'DATE_OFFENSE_COMMITTED_-_BEGIN',\\\n",
    "                                   'MINIMUM_SENTENCE_LENGTH', 'MAXIMUM_SENTENCE_LENGTH',\\\n",
    "                                   'LENGTH_OF_SUPERVISION', 'SENTENCE_EFFECTIVE(BEGIN)_DATE',\\\n",
    "                                   'INMATE_COMPONENT_STATUS_DATE', 'PRIMARY_FELONY/MISDEMEANOR_CD._FELON',\\\n",
    "                                   'PRIMARY_FELONY/MISDEMEANOR_CD._MISD.',\\\n",
    "                                   'PRIMARY_FELONY/MISDEMEANOR_CD._UNKN.',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_ACTIVE  SS',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_COMMUNITY SS (DCC)', 'PUNISHMENT_TYPE_CODE_DWI',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_FAIR FELONS',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_FAIR MISDEMEAN',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_INTERMEDIATE SS',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_NON JUDGMENT CASES',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_NON-N.C. OFF.',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_POST RELEASE', 'PUNISHMENT_TYPE_CODE_PRE-FAIR',\\\n",
    "                                   'PUNISHMENT_TYPE_CODE_PRE-SS (FAIR) DCC', 'PUNISHMENT_TYPE_CODE_PSI',\\\n",
    "                                   'COURT_TYPE_CODE_CO RECORDR', 'COURT_TYPE_CODE_DISTRICT',\\\n",
    "                                   'COURT_TYPE_CODE_DOMES RELA', 'COURT_TYPE_CODE_ICC/OS/FED',\\\n",
    "                                   'COURT_TYPE_CODE_J.P.', 'COURT_TYPE_CODE_MAGISTRAT',\\\n",
    "                                   'COURT_TYPE_CODE_MAYORS', 'COURT_TYPE_CODE_SUPERIOR',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_APPEAL',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_BENCH TRIAL',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_CRV/3M',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_GUILTY',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_JUDGMENT',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_JURY TRIAL',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_NEGOTIATED PLEA',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_NOLO CONTENDRE',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_NON-JUDGMENT',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_NOT GUILTY',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_PARTIAL REVOKE',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_POST REL. REVOKED',\\\n",
    "                                   'COMPONENT_DISPOSITION_CODE_UNKNOWN',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_ACCES A/F', 'OFFENSE_QUALIFIER_CODE_ACCES ATT',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_ACCES B/F', 'OFFENSE_QUALIFIER_CODE_AID&ABET',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_ATTEMPTED', 'OFFENSE_QUALIFIER_CODE_CONSPI ATT',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_CONSPIRACY', 'OFFENSE_QUALIFIER_CODE_PRINCIPAL',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_SOLIC ATT', 'OFFENSE_QUALIFIER_CODE_SOLICIT',\\\n",
    "                                   'OFFENSE_QUALIFIER_CODE_UNKNOWN', 'INMATE_SENTENCE_STATUS_CODE_ACTIVE',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_AMENDED',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_ARRESTED',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_CANCEL',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_COMM T/S',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_COMMUTAT',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_CORRECT',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_COURT OR',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_DISMISS',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_MODIFIED',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_P & T',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_PAR CONS',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_PARDON',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_PC TERM',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_QUASHED',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_REINSTATE',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_RESENTEN',\\\n",
    "                                   'INMATE_SENTENCE_STATUS_CODE_VACATED',\\\n",
    "                                   'SERVING_MIN_OR_MAX_TERM_CODE_MAX.TERM:',\\\n",
    "                                   'SERVING_MIN_OR_MAX_TERM_CODE_MIN.TERM:'])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Sentence_Component.to_csv(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Special_Cond_Sanctions\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/OFNT3DE1.csv\")\n",
    "Special_Cond = pd.read_csv(file_name, low_memory=False)#, nrows=40000)\n",
    "Special_Cond = keep_attribute(Special_Cond,[\"OFFENDER_NC_DOC_ID_NUMBER\",\\\n",
    "                                            \"COMMITMENT_PREFIX\",\\\n",
    "                                            \"SENTENCE_COMPONENT_NUMBER\",\\\n",
    "                                            \"SPECIAL_PROVISION/SANCTION_CD\",\\\n",
    "                                            \"COMPLETION_STATUS_OF_SANCTION\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Special_Cond.to_csv(new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Parole_Analyst\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/INMT4CA1.csv\")\n",
    "Parole_Analyst = pd.read_csv(file_name, low_memory=False)#, nrows=40000)\n",
    "Parole_Analyst = categorical_to_dummy(Parole_Analyst, ['NEXT_PAROLE_REVIEW_TYPE_CODE'])\n",
    "Parole_Analyst = to_date(Parole_Analyst, [\"RELEASE_DATE_(PAROLE_REVIEW)\"])\n",
    "Parole_Analyst = keep_attribute(Parole_Analyst,   ['INMATE_DOC_NUMBER', 'RELEASE_DATE_(PAROLE_REVIEW)',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_AFTERCARE TRT.',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_COMMISSION REVW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_INTERIM REVIEW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_MAPP REVIEW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_PAROLE REVIEW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_RT DRUG TEST',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_VOTE REVIEW',\\\n",
    "                                                   'NEXT_PAROLE_REVIEW_TYPE_CODE_WORK RELEASE'])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Parole_Analyst.to_csv(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(os.path.join(data_dir, \"crimes.db\"))\n",
    "cur = con.cursor()\n",
    "\n",
    "tables = ['INMT4AA1_cleaned', 'INMT4BB1_cleaned', 'INMT9CF1_cleaned',\\\n",
    "          'OFNT1BA1_cleaned', 'OFNT3BB1_cleaned', 'OFNT3CE1_cleaned',\\\n",
    "          'OFNT3DE1_cleaned', 'INMT4CA1_cleaned']\n",
    "\n",
    "for table in tables:\n",
    "    #print(table)\n",
    "    file_name = os.path.join(data_dir, \"preprocessed/{}.csv\".format(table)) \n",
    "    col_names = pd.read_csv(file_name, nrows=0).columns\n",
    "    n_columns = len(col_names)\n",
    "    col_names = clean_str(', '.join(col_names))\n",
    "    cur.execute('DROP TABLE IF EXISTS {}'.format(table))\n",
    "    cur.execute(\"CREATE TABLE {} ({});\".format(table, col_names))\n",
    "    \n",
    "    #File contains NULL bytes. That's why I replaced '\\0' with ''\n",
    "    reader = csv.reader(x.replace('\\0','') for x in open(file_name))\n",
    "    for row in reader:\n",
    "        row = [None if x == '' else x for x in row]\n",
    "        cur.execute(\"INSERT INTO {} VALUES ({});\".format(table,\",\".join(['?']*n_columns)), row)\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWarrant_Issued = pd.read_csv(\"data/preprocessed/OFNT9BE1.csv\")\\nOffender_profile = pd.read_csv(\"data/preprocessed/OFNT3AA1.csv\")\\n\\nInfraction_Charge.groupby(\"SUSPENSION_STATUS\").size()\\n\\n#Print type of data on the df:\\n\\nfor at in Inmate_Profile.columns:\\n    print(at)\\n    print(type(Inmate_Profile[at][0]))\\n\\n#Cleaning Court Commitment\\n\\nfile_name = os.path.join(data_dir, \"preprocessed/OFNT3BB1.csv\")\\nCourt_Commitment = pd.read_csv(file_name, low_memory=False, nrows=40000)\\nCourt_Commitment = categorical_to_dummy(Court_Commitment, [\"COURT_ORDERED_PAYMENT_TYPE\"])\\nCourt_Commitment = flag_to_dummy(Court_Commitment, [\"PAYEE_ACCOUNT_STATUS_CODE\"], rename=False)\\n#Court_Commitment = discretize_variable(Court_Commitment, [\"COP_BALANCE\"])\\nCourt_Commitment =  keep_attribute(Court_Commitment, [\"OFFENDER_NC_DOC_ID_NUMBER\", \"COP_COMMITMENT_PREFIX\",                                      \"COP_ACCOUNT_SEQUENCE_NUMBER\",\"COURT_ORDERED_PAYMENT_TYPE_FINE\",                                      \"COURT_ORDERED_PAYMENT_TYPE_COMM. SERVICE FEE\",\"PAYEE_ACCOUNT_STATUS_CODE\",                                      \"COURT_ORDERED_PAYMENT_TYPE_COURT COSTS\",\"COURT_ORDERED_PAYMENT_TYPE_JAIL FEE\",                                      \"COURT_ORDERED_PAYMENT_TYPE_JUDGEMENT\",\"COURT_ORDERED_PAYMENT_TYPE_RESTITUTION\",                                      \"COURT_ORDERED_PAYMENT_TYPE_SUPERVISION FEE\", \"COP_BALANCEcat\"])\\n\\nnew_file_name = file_name[:-4] + \\'_cleaned.csv\\'\\nCourt_Commitment.to_csv(new_file_name)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OTHER:\n",
    "'''\n",
    "Warrant_Issued = pd.read_csv(\"data/preprocessed/OFNT9BE1.csv\")\n",
    "Offender_profile = pd.read_csv(\"data/preprocessed/OFNT3AA1.csv\")\n",
    "\n",
    "Infraction_Charge.groupby(\"SUSPENSION_STATUS\").size()\n",
    "\n",
    "#Print type of data on the df:\n",
    "\n",
    "for at in Inmate_Profile.columns:\n",
    "    print(at)\n",
    "    print(type(Inmate_Profile[at][0]))\n",
    "\n",
    "#Cleaning Court Commitment\n",
    "\n",
    "file_name = os.path.join(data_dir, \"preprocessed/OFNT3BB1.csv\")\n",
    "Court_Commitment = pd.read_csv(file_name, low_memory=False, nrows=40000)\n",
    "Court_Commitment = categorical_to_dummy(Court_Commitment, [\"COURT_ORDERED_PAYMENT_TYPE\"])\n",
    "Court_Commitment = flag_to_dummy(Court_Commitment, [\"PAYEE_ACCOUNT_STATUS_CODE\"], rename=False)\n",
    "#Court_Commitment = discretize_variable(Court_Commitment, [\"COP_BALANCE\"])\n",
    "Court_Commitment =  keep_attribute(Court_Commitment, [\"OFFENDER_NC_DOC_ID_NUMBER\", \"COP_COMMITMENT_PREFIX\",\\\n",
    "                                      \"COP_ACCOUNT_SEQUENCE_NUMBER\",\"COURT_ORDERED_PAYMENT_TYPE_FINE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_COMM. SERVICE FEE\",\"PAYEE_ACCOUNT_STATUS_CODE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_COURT COSTS\",\"COURT_ORDERED_PAYMENT_TYPE_JAIL FEE\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_JUDGEMENT\",\"COURT_ORDERED_PAYMENT_TYPE_RESTITUTION\",\\\n",
    "                                      \"COURT_ORDERED_PAYMENT_TYPE_SUPERVISION FEE\", \"COP_BALANCEcat\"])\n",
    "\n",
    "new_file_name = file_name[:-4] + '_cleaned.csv'\n",
    "Court_Commitment.to_csv(new_file_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN  SentenceComputation and Cleaning Inmate Profile\n",
    "Inmate_Profile[\"INMATE_DOC_NUMBER\"] = Inmate_Profile[\"INMATE_DOC_NUMBER\"].astype(str)\n",
    "Sentence_Computation[\"INMATE_DOC_NUMBER\"] = Sentence_Computation[\"INMATE_DOC_NUMBER\"].astype(str)\n",
    "Inmate_Sentence = Sentence_Computation.join(Inmate_Profile, on=\"INMATE_DOC_NUMBER\", how='left',  rsuffix='2')\n",
    "Inmate_Sentence.dropna(axis=0, inplace=True, subset=[\"INMATE_DOC_NUMBER2\"])\n",
    "Inmate_Sentence['dup'] = ~Inmate_Sentence.duplicated(subset=\"INMATE_DOC_NUMBER\", keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The table of Inmate_Profile&Sentence has 644860 total felonies commited - Those correspond to 154099 unique persons.Out of them there are 19166.0 females and 134933.0 males, this means that 0.8756254096392576% are males. There are 639047 people that had prior incarcelations and there are 23252.0 inmates that have a history of scaping.In terms of race, there are 80751.0 black people, 3078.0 indian, 63144.0 white and 6738.0 of other or unknown race'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The table of Inmate_Profile&Sentence has {} total felonies commited - Those correspond to {} unique persons.\\\n",
    "Out of them there are {} females and {} males, this means that {}% are males. There are {} people that had \\\n",
    "prior incarcelations and there are {} inmates that have a history of scaping.\\\n",
    "In terms of race, there are {} black people, {} indian, {} white and {} of other or unknown race\".\\\n",
    "format(Inmate_Sentence['INMATE_DOC_NUMBER2'].count(), Inmate_Sentence['dup'].sum(),\\\n",
    "(Inmate_Sentence['dup']*Inmate_Sentence['FEMALE']).sum(), (Inmate_Sentence['dup']*(1-Inmate_Sentence['FEMALE'])).sum(),\\\n",
    "((Inmate_Sentence['dup']*(1-Inmate_Sentence['FEMALE'])/ Inmate_Sentence['dup'].sum()).sum()),\\\n",
    "(Inmate_Sentence['PRIOR_INCARCERATIONS']*Inmate_Sentence['dup']).count(), Inmate_Sentence['ESCAPE_HISTORY'].sum(),\\\n",
    "(Inmate_Sentence['dup']*Inmate_Sentence['INMATE_RACE_CODE_BLACK']).sum(),(Inmate_Sentence['dup']*Inmate_Sentence['INMATE_RACE_CODE_INDIAN']).sum(),\\\n",
    "(Inmate_Sentence['dup']*Inmate_Sentence['INMATE_RACE_CODE_WHITE']).sum(),\\\n",
    "((Inmate_Sentence['dup']*Inmate_Sentence['INMATE_RACE_CODE_OTHER']).sum()+(Inmate_Sentence['dup']*Inmate_Sentence['INMATE_RACE_CODE_UNKNOWN']).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9646726854913155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dup    PRIOR_INCARCERATIONS\n",
       "False  0.0                      17526\n",
       "       1.0                     468778\n",
       "True   0.0                       5396\n",
       "       1.0                     147347\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(147347/(5396+147347))\n",
    "Inmate_Sentence.groupby(['dup', 'PRIOR_INCARCERATIONS']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The data base that we will work with has 1704951 total sentences that correspond to 461681 unique persons'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The data base that we will work with has {} total sentences that correspond to {} unique persons\".format(\\\n",
    "        Sentence_Computation['INMATE_DOC_NUMBER'].count(),Sentence_Computation['INMATE_DOC_NUMBER'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The table of Inmate Profile has 296560 total inmates that commited felonies - 296560 correspond to unique persons. There are 282966.0 persons that had prior incarcelations and there are 10706 inmates that have a history of scaping'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The table of Inmate Profile has {} total inmates that commited felonies - {} correspond to unique persons. \\\n",
    "There are {} persons that had prior incarcelations and there are {} inmates that have a history \\\n",
    "of scaping\".format(Inmate_Profile['INMATE_DOC_NUMBER'].count(),Inmate_Profile['INMATE_DOC_NUMBER'].nunique(),\\\n",
    "                   Inmate_Profile['PRIOR_INCARCERATIONS'].sum(), Inmate_Profile['ESCAPE_HISTORY'].sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
